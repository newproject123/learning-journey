Brief Summary
perceptron - attempt to mimick biological neurons. Takes wieghted inputs and returns an output
activation function - decides if a neuron fires or not. squashes the output of neurons into an output signal
  --> relu - type of activation function that returns x for x>0
linear seperability- can be separated by a straight line
backpropagation - model trains on itself using the loss function & runs back through model to correct
 --> enables multi dimensional solutions or non linear data
multilayer feed forward - uses backpropagation to bypass XOR
Time delay NN - speech recognition
 --> one dimensional CNN
 LeNet - earliest named CNN
 convolution - sliding "image frame" sort of filter that scans an image
 depthwise convolution - each input channel gets its own filter
 pointwise convolution - 1x1 filters across all channels mix the outputs
 
